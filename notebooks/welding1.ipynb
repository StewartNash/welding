{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NTLFgYoxjDHO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TOTAL_ROWS = 10000\n",
        "\n",
        "COLUMNS = [\n",
        "    'electrode force',\n",
        "    'electrode contact surface diameter',\n",
        "    'squeeze time',\n",
        "    'weld time',\n",
        "    'hold time',\n",
        "    'weld current',\n",
        "    'leak rate',\n",
        "    'explosive force',\n",
        "    'leaking',\n",
        "    'explosion'\n",
        "]\n",
        "\n",
        "INPUT_COLUMNS = [\n",
        "    'electrode force',\n",
        "    'electrode contact surface diameter',\n",
        "    'squeeze time',\n",
        "    'weld time',\n",
        "    'hold time',\n",
        "    'weld current'\n",
        "]\n",
        "\n",
        "OUTPUT_COLUMNS = [\n",
        "    'leak rate',\n",
        "    'explosive force',\n",
        "    'leaking',\n",
        "    'explosion'\n",
        "]\n",
        "\n",
        "CATEGORICAL_LABELS = ['leaking', 'explosion']"
      ],
      "metadata": {
        "id": "oNHvSdY8jFDI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_coefficients(input_length, output_length):\n",
        "    mean = 0\n",
        "    stddev = 5.0\n",
        "    rows = input_length\n",
        "    columns = output_length\n",
        "    return np.random.normal(mean, stddev, size=(rows, columns))\n",
        "\n",
        "def generate_row(coefficients):\n",
        "    rows, columns = coefficients.shape\n",
        "    input_row = np.random.rand(columns)\n",
        "    output = np.matmul(coefficients, input_row)\n",
        "    output = output.tolist()\n",
        "    assert len(output) >= 4\n",
        "    output[-2] = \"leaking\" if output[-4] > 0 else \"not leaking\"\n",
        "    output[-1] = \"explosion\" if output[-3] > 0 else \"no explosion\"\n",
        "    output = input_row.tolist() + output\n",
        "    return output\n",
        "\n",
        "def generate_sets(myset, output_columns, categorical_labels):\n",
        "    myset_labels = myset[output_columns].copy()\n",
        "    myset = myset.drop(output_columns, axis=1)\n",
        "    myset_categorical = myset_labels[categorical_labels]\n",
        "    categorical_encoder = OneHotEncoder()\n",
        "    myset_categorical = categorical_encoder.fit_transform(myset_categorical)\n",
        "    myset_categorical = myset_categorical.toarray()\n",
        "    return myset, myset_labels, myset_categorical, categorical_encoder"
      ],
      "metadata": {
        "id": "45iymD_OjVS7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_dataframe = pd.DataFrame(columns=COLUMNS)\n",
        "coefficients = generate_coefficients(len(INPUT_COLUMNS), len(OUTPUT_COLUMNS))\n",
        "for i in range(TOTAL_ROWS):\n",
        "    my_dataframe.loc[len(my_dataframe)] = generate_row(coefficients)\n",
        "print(my_dataframe.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nhu-V5Dtjhcc",
        "outputId": "ec39f3ae-d87c-47b7-b7cb-e35d6f1a4ff9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   electrode force  electrode contact surface diameter  squeeze time  \\\n",
            "0         0.389669                            0.094160      0.695286   \n",
            "1         0.670343                            0.815768      0.156309   \n",
            "2         0.739572                            0.890730      0.737805   \n",
            "3         0.578696                            0.358253      0.886858   \n",
            "4         0.880160                            0.702583      0.490532   \n",
            "\n",
            "   weld time  hold time  weld current  leak rate  explosive force  leaking  \\\n",
            "0   0.905132  10.360130      3.715172   3.017622         8.794391  leaking   \n",
            "1   0.985270   7.689220      1.268376   4.881699        15.784624  leaking   \n",
            "2   0.585895  11.049623      0.342335   2.434512        10.416735  leaking   \n",
            "3   0.618554  11.459582      1.735881   1.998466         7.508179  leaking   \n",
            "4   0.524486   8.864821     -1.346961   3.095410        11.536425  leaking   \n",
            "\n",
            "   explosion  \n",
            "0  explosion  \n",
            "1  explosion  \n",
            "2  explosion  \n",
            "3  explosion  \n",
            "4  explosion  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "welding_train, welding_test = train_test_split(my_dataframe, test_size=0.2, random_state=42)\n",
        "welding_train, welding_validation = train_test_split(welding_train)\n",
        "\n",
        "welding_train_labels = welding_train[OUTPUT_COLUMNS].copy()\n",
        "welding_train = welding_train.drop(OUTPUT_COLUMNS, axis=1)\n",
        "welding_train_categorical = welding_train_labels[CATEGORICAL_LABELS]\n",
        "welding_train_labels = welding_train_labels.drop(CATEGORICAL_LABELS, axis=1)\n",
        "train_categorical_encoder = OneHotEncoder()\n",
        "welding_train_categorical = train_categorical_encoder.fit_transform(welding_train_categorical)\n",
        "welding_train_categorical = welding_train_categorical.toarray()\n",
        "\n",
        "welding_test_labels = welding_test[OUTPUT_COLUMNS].copy()\n",
        "welding_test = welding_test.drop(OUTPUT_COLUMNS, axis=1)\n",
        "welding_test_categorical = welding_test_labels[CATEGORICAL_LABELS]\n",
        "welding_test_labels = welding_test_labels.drop(CATEGORICAL_LABELS, axis=1)\n",
        "test_categorical_encoder = OneHotEncoder()\n",
        "welding_test_categorical = test_categorical_encoder.fit_transform(welding_test_categorical)\n",
        "welding_test_categorical = welding_test_categorical.toarray()\n",
        "\n",
        "welding_validation_labels = welding_validation[OUTPUT_COLUMNS].copy()\n",
        "welding_validation = welding_validation.drop(OUTPUT_COLUMNS, axis=1)\n",
        "welding_validation_categorical = welding_validation_labels[CATEGORICAL_LABELS]\n",
        "welding_validation_labels = welding_validation_labels.drop(CATEGORICAL_LABELS, axis=1)\n",
        "validation_categorical_encoder = OneHotEncoder()\n",
        "welding_validation_categorical = validation_categorical_encoder.fit_transform(welding_validation_categorical)\n",
        "welding_validation_categorical = welding_validation_categorical.toarray()\n",
        "\n",
        "scaler = StandardScaler()\n",
        "welding_train = scaler.fit_transform(welding_train)\n",
        "welding_test = scaler.transform(welding_test)\n",
        "welding_validation = scaler.transform(welding_validation)\n",
        "\n",
        "print(welding_train_categorical[:10])\n",
        "print(train_categorical_encoder.categories_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQnKJ1Wmjjpw",
        "outputId": "4d1dd098-488b-4cac-dde7-b1b78771c281"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 1. 0.]\n",
            " [1. 0. 1. 0.]\n",
            " [1. 0. 1. 0.]\n",
            " [1. 0. 1. 0.]\n",
            " [1. 0. 1. 0.]\n",
            " [1. 0. 1. 0.]\n",
            " [1. 0. 1. 0.]\n",
            " [1. 0. 1. 0.]\n",
            " [1. 0. 1. 0.]\n",
            " [1. 0. 1. 0.]]\n",
            "[array(['leaking', 'not leaking'], dtype=object), array(['explosion', 'no explosion'], dtype=object)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "ZFoXFuPYjo52"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_WIDTH = len(INPUT_COLUMNS)\n",
        "OUTPUT_WIDTH = len(OUTPUT_COLUMNS)\n",
        "numerical_output_width = welding_train_labels.shape[1]\n",
        "categorical_output_width = welding_train_categorical.shape[1]"
      ],
      "metadata": {
        "id": "MC66uiMZjq12"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.InputLayer(input_shape=(INPUT_WIDTH,)))\n",
        "model.add(keras.layers.Dense(INPUT_WIDTH * 10, activation=\"relu\"))\n",
        "model.add(keras.layers.Dense(INPUT_WIDTH * 5, activation=\"relu\"))\n",
        "model.add(keras.layers.Dense(INPUT_WIDTH * 1, activation=\"relu\"))\n",
        "#model.add(keras.layers.Dense(numerical_output_width, activation=\"softmax\"))\n",
        "model.add(keras.layers.Dense(numerical_output_width))\n",
        "#model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
        "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mse\"])\n",
        "history = model.fit(welding_train,\n",
        "    welding_train_labels,\n",
        "    epochs=30,\n",
        "    validation_data=(welding_validation, welding_validation_labels))\n",
        "mse_test = model.evaluate(welding_test, welding_test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bm4pZYpSjv8V",
        "outputId": "a624b1cf-a709-4342-e6ee-616d1f470288"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 23.5055 - mse: 23.5055 - val_loss: 0.9671 - val_mse: 0.9671\n",
            "Epoch 2/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.8311 - mse: 0.8311 - val_loss: 0.4338 - val_mse: 0.4338\n",
            "Epoch 3/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3431 - mse: 0.3431 - val_loss: 0.1487 - val_mse: 0.1487\n",
            "Epoch 4/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1072 - mse: 0.1072 - val_loss: 0.0360 - val_mse: 0.0360\n",
            "Epoch 5/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0162 - val_mse: 0.0162\n",
            "Epoch 6/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0109 - val_mse: 0.0109\n",
            "Epoch 7/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0080 - val_mse: 0.0080\n",
            "Epoch 8/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0062 - val_mse: 0.0062\n",
            "Epoch 9/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0050 - val_mse: 0.0050\n",
            "Epoch 10/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0043 - val_mse: 0.0043\n",
            "Epoch 11/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0039 - val_mse: 0.0039\n",
            "Epoch 12/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0034 - val_mse: 0.0034\n",
            "Epoch 13/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0032 - val_mse: 0.0032\n",
            "Epoch 14/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0024 - val_mse: 0.0024\n",
            "Epoch 15/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0026 - val_mse: 0.0026\n",
            "Epoch 16/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 17/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 18/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 19/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 20/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0016 - val_mse: 0.0016\n",
            "Epoch 21/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0013 - val_mse: 0.0013\n",
            "Epoch 22/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0015 - val_mse: 0.0015\n",
            "Epoch 23/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0012 - val_mse: 0.0012\n",
            "Epoch 24/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 25/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0012 - val_mse: 0.0012\n",
            "Epoch 26/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 9.6589e-04 - val_mse: 9.6589e-04\n",
            "Epoch 27/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 9.1996e-04 - val_mse: 9.1996e-04\n",
            "Epoch 28/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 8.6147e-04 - mse: 8.6147e-04 - val_loss: 0.0013 - val_mse: 0.0013\n",
            "Epoch 29/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9.1025e-04 - mse: 9.1025e-04 - val_loss: 0.0013 - val_mse: 0.0013\n",
            "Epoch 30/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9.6875e-04 - mse: 9.6875e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - mse: 0.0011\n"
          ]
        }
      ]
    }
  ]
}