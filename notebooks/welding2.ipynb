{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NTLFgYoxjDHO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TOTAL_ROWS = 10000\n",
        "\n",
        "COLUMNS = [\n",
        "    'electrode force',\n",
        "    'electrode contact surface diameter',\n",
        "    'squeeze time',\n",
        "    'weld time',\n",
        "    'hold time',\n",
        "    'weld current',\n",
        "    'leak rate',\n",
        "    'explosive force',\n",
        "    'leaking',\n",
        "    'explosion'\n",
        "]\n",
        "\n",
        "INPUT_COLUMNS = [\n",
        "    'electrode force',\n",
        "    'electrode contact surface diameter',\n",
        "    'squeeze time',\n",
        "    'weld time',\n",
        "    'hold time',\n",
        "    'weld current'\n",
        "]\n",
        "\n",
        "OUTPUT_COLUMNS = [\n",
        "    'leak rate',\n",
        "    'explosive force',\n",
        "    'leaking',\n",
        "    'explosion'\n",
        "]\n",
        "\n",
        "CATEGORICAL_LABELS = ['leaking', 'explosion']\n",
        "REGRESSION_LABELS = ['leak rate', 'explosive force']"
      ],
      "metadata": {
        "id": "oNHvSdY8jFDI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_coefficients(input_length, output_length):\n",
        "    mean = 0\n",
        "    stddev = 5.0\n",
        "    rows = input_length\n",
        "    columns = output_length\n",
        "    return np.random.normal(mean, stddev, size=(rows, columns))\n",
        "\n",
        "def generate_row(coefficients):\n",
        "    rows, columns = coefficients.shape\n",
        "    input_row = np.random.rand(columns)\n",
        "    output = np.matmul(coefficients, input_row)\n",
        "    output = output.tolist()\n",
        "    assert len(output) >= 4\n",
        "    output[-2] = \"leaking\" if output[-4] > 0 else \"not leaking\"\n",
        "    output[-1] = \"explosion\" if output[-3] > 0 else \"no explosion\"\n",
        "    output = input_row.tolist() + output\n",
        "    return output\n",
        "\n",
        "def generate_sets(myset, output_columns, categorical_labels):\n",
        "    myset_labels = myset[output_columns].copy()\n",
        "    myset = myset.drop(output_columns, axis=1)\n",
        "    myset_categorical = myset_labels[categorical_labels]\n",
        "    myset_labels.drop(categorical_labels, axis=1)\n",
        "    categorical_encoder = OneHotEncoder(sparse_output=False)\n",
        "    myset_categorical = categorical_encoder.fit_transform(myset_categorical)\n",
        "    return myset, myset_labels, myset_categorical, categorical_encoder"
      ],
      "metadata": {
        "id": "45iymD_OjVS7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_dataframe = pd.DataFrame(columns=COLUMNS)\n",
        "coefficients = generate_coefficients(len(INPUT_COLUMNS), len(OUTPUT_COLUMNS))\n",
        "for i in range(TOTAL_ROWS):\n",
        "    my_dataframe.loc[len(my_dataframe)] = generate_row(coefficients)\n",
        "print(my_dataframe.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nhu-V5Dtjhcc",
        "outputId": "e20c31ca-53b6-4b6b-a4ef-a484a7750b2b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   electrode force  electrode contact surface diameter  squeeze time  \\\n",
            "0         0.868532                            0.851671      0.758218   \n",
            "1         0.279985                            0.334890      0.535683   \n",
            "2         0.172211                            0.446364      0.486299   \n",
            "3         0.386395                            0.265596      0.589903   \n",
            "4         0.971657                            0.272425      0.217422   \n",
            "\n",
            "   weld time  hold time  weld current  leak rate  explosive force  \\\n",
            "0   0.256115   2.513977     22.226443  -6.271782       -18.181455   \n",
            "1   0.374953   1.202295     11.884132  -4.725227        -7.015464   \n",
            "2   0.189616   0.451185     10.892596  -3.773565        -6.331197   \n",
            "3   0.946366   2.861346     14.119183  -7.051818        -8.031213   \n",
            "4   0.578170   4.240190     12.810629  -4.094655       -14.202506   \n",
            "\n",
            "       leaking     explosion  \n",
            "0  not leaking  no explosion  \n",
            "1  not leaking  no explosion  \n",
            "2  not leaking  no explosion  \n",
            "3  not leaking  no explosion  \n",
            "4  not leaking  no explosion  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test = train_test_split(my_dataframe, test_size=0.2, random_state=42)\n",
        "X_train, X_validation = train_test_split(X_train)\n",
        "\n",
        "X_train_labels = X_train[OUTPUT_COLUMNS].copy()\n",
        "X_train = X_train.drop(OUTPUT_COLUMNS, axis=1)\n",
        "X_train_categorical = X_train_labels[CATEGORICAL_LABELS]\n",
        "X_train_labels = X_train_labels.drop(CATEGORICAL_LABELS, axis=1)\n",
        "train_categorical_encoder = OneHotEncoder(sparse_output=False)\n",
        "X_train_categorical = train_categorical_encoder.fit_transform(X_train_categorical)\n",
        "\n",
        "X_test_labels = X_test[OUTPUT_COLUMNS].copy()\n",
        "X_test = X_test.drop(OUTPUT_COLUMNS, axis=1)\n",
        "X_test_categorical = X_test_labels[CATEGORICAL_LABELS]\n",
        "X_test_labels = X_test_labels.drop(CATEGORICAL_LABELS, axis=1)\n",
        "test_categorical_encoder = OneHotEncoder(sparse_output=False)\n",
        "X_test_categorical = test_categorical_encoder.fit_transform(X_test_categorical)\n",
        "\n",
        "X_validation_labels = X_validation[OUTPUT_COLUMNS].copy()\n",
        "X_validation = X_validation.drop(OUTPUT_COLUMNS, axis=1)\n",
        "X_validation_categorical = X_validation_labels[CATEGORICAL_LABELS]\n",
        "X_validation_labels = X_validation_labels.drop(CATEGORICAL_LABELS, axis=1)\n",
        "validation_categorical_encoder = OneHotEncoder(sparse_output=False)\n",
        "X_validation_categorical = validation_categorical_encoder.fit_transform(X_validation_categorical)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "X_validation = scaler.transform(X_validation)\n",
        "\n",
        "print(X_train_categorical[:10])\n",
        "print(train_categorical_encoder.categories_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQnKJ1Wmjjpw",
        "outputId": "1119afc4-d3f0-4260-e481-fcedeedceee4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 1.]\n",
            " [1. 1.]\n",
            " [1. 1.]\n",
            " [1. 1.]\n",
            " [1. 1.]\n",
            " [1. 1.]\n",
            " [1. 1.]\n",
            " [1. 1.]\n",
            " [1. 1.]\n",
            " [1. 1.]]\n",
            "[array(['not leaking'], dtype=object), array(['no explosion'], dtype=object)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_regression = X_train_labels\n",
        "y_train_classification = X_train_categorical\n",
        "y_test_regression = X_test_labels\n",
        "y_test_classification = X_test_categorical\n",
        "y_validation_regression = X_validation_labels\n",
        "y_validation_classification = X_validation_categorical"
      ],
      "metadata": {
        "id": "FemMa-op32HU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "ZFoXFuPYjo52"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_WIDTH = len(INPUT_COLUMNS)\n",
        "OUTPUT_WIDTH = len(OUTPUT_COLUMNS)\n",
        "CLASSIFICATION_LABELS = CATEGORICAL_LABELS"
      ],
      "metadata": {
        "id": "MC66uiMZjq12"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(INPUT_WIDTH,), name=\"input\")\n",
        "x = keras.layers.Dense(INPUT_WIDTH * 10, activation=\"relu\")(inputs)\n",
        "x = keras.layers.Dense(INPUT_WIDTH * 5, activation=\"relu\")(x)\n",
        "regression_output = keras.layers.Dense(len(REGRESSION_LABELS), name=\"regression\")(x)\n",
        "classification_output = keras.layers.Dense(\n",
        "    len(CLASSIFICATION_LABELS),\n",
        "    activation=\"sigmoid\",\n",
        "    name=\"classification\")(x)\n",
        "model = keras.Model(\n",
        "    inputs=inputs,\n",
        "    outputs=[regression_output, classification_output],\n",
        "    name=\"multi_output_model\")\n",
        "model.compile(\n",
        "    loss={\"regression\": \"mse\", \"classification\": \"categorical_crossentropy\"},\n",
        "    optimizer=\"adam\",\n",
        "    metrics={\"regression\": [\"mae\"], \"classification\": [\"accuracy\"]})\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    {\"regression\": y_train_regression, \"classification\": y_train_classification},\n",
        "    validation_data=(X_validation, {\"regression\": y_validation_regression, \"classification\": y_validation_classification}),\n",
        "    epochs=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bm4pZYpSjv8V",
        "outputId": "2cb6388c-bdae-42d1-f8e8-be30d9339e14"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - classification_accuracy: 0.0479 - classification_loss: 2.1999 - loss: 50.7271 - regression_loss: 48.5266 - regression_mae: 5.7181 - val_classification_accuracy: 0.0000e+00 - val_classification_loss: 2.6133 - val_loss: 5.4961 - val_regression_loss: 2.8834 - val_regression_mae: 1.3299\n",
            "Epoch 2/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - classification_accuracy: 0.0000e+00 - classification_loss: 2.4391 - loss: 4.7120 - regression_loss: 2.2729 - regression_mae: 1.1555 - val_classification_accuracy: 0.0000e+00 - val_classification_loss: 2.6775 - val_loss: 4.2103 - val_regression_loss: 1.5306 - val_regression_mae: 0.9384\n",
            "Epoch 3/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - classification_accuracy: 0.0020 - classification_loss: 2.8171 - loss: 4.4079 - regression_loss: 1.5908 - regression_mae: 0.9656 - val_classification_accuracy: 0.0085 - val_classification_loss: 3.1115 - val_loss: 4.9646 - val_regression_loss: 1.8468 - val_regression_mae: 1.0258\n",
            "Epoch 4/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - classification_accuracy: 0.0195 - classification_loss: 3.3916 - loss: 5.5386 - regression_loss: 2.1470 - regression_mae: 1.1354 - val_classification_accuracy: 0.0360 - val_classification_loss: 3.8954 - val_loss: 6.1836 - val_regression_loss: 2.2797 - val_regression_mae: 1.1802\n",
            "Epoch 5/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - classification_accuracy: 0.0689 - classification_loss: 4.3121 - loss: 7.0226 - regression_loss: 2.7106 - regression_mae: 1.2916 - val_classification_accuracy: 0.1180 - val_classification_loss: 4.0286 - val_loss: 7.2444 - val_regression_loss: 3.2061 - val_regression_mae: 1.4602\n",
            "Epoch 6/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - classification_accuracy: 0.1210 - classification_loss: 4.4911 - loss: 8.6874 - regression_loss: 4.1962 - regression_mae: 1.5944 - val_classification_accuracy: 0.2330 - val_classification_loss: 3.8997 - val_loss: 7.5693 - val_regression_loss: 3.6612 - val_regression_mae: 1.5130\n",
            "Epoch 7/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - classification_accuracy: 0.1799 - classification_loss: 4.9338 - loss: 10.0487 - regression_loss: 5.1148 - regression_mae: 1.7737 - val_classification_accuracy: 0.0745 - val_classification_loss: 5.4477 - val_loss: 14.1702 - val_regression_loss: 8.7001 - val_regression_mae: 2.1092\n",
            "Epoch 8/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - classification_accuracy: 0.2230 - classification_loss: 5.3635 - loss: 12.1985 - regression_loss: 6.8350 - regression_mae: 1.9971 - val_classification_accuracy: 0.5755 - val_classification_loss: 4.4435 - val_loss: 15.5540 - val_regression_loss: 11.1348 - val_regression_mae: 2.7788\n",
            "Epoch 9/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - classification_accuracy: 0.2503 - classification_loss: 5.3091 - loss: 14.1028 - regression_loss: 8.7936 - regression_mae: 2.2645 - val_classification_accuracy: 0.4710 - val_classification_loss: 4.5822 - val_loss: 12.6305 - val_regression_loss: 8.0627 - val_regression_mae: 2.2014\n",
            "Epoch 10/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - classification_accuracy: 0.3001 - classification_loss: 5.8821 - loss: 14.3322 - regression_loss: 8.4505 - regression_mae: 2.2300 - val_classification_accuracy: 0.4485 - val_classification_loss: 4.8868 - val_loss: 10.5073 - val_regression_loss: 5.6092 - val_regression_mae: 1.9055\n",
            "Epoch 11/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - classification_accuracy: 0.3118 - classification_loss: 6.0965 - loss: 19.4438 - regression_loss: 13.3470 - regression_mae: 2.7775 - val_classification_accuracy: 0.5255 - val_classification_loss: 5.2987 - val_loss: 15.3340 - val_regression_loss: 10.0215 - val_regression_mae: 2.6101\n",
            "Epoch 12/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - classification_accuracy: 0.3240 - classification_loss: 6.5261 - loss: 17.6742 - regression_loss: 11.1481 - regression_mae: 2.6142 - val_classification_accuracy: 0.0795 - val_classification_loss: 7.9451 - val_loss: 17.5759 - val_regression_loss: 9.6308 - val_regression_mae: 2.6282\n",
            "Epoch 13/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - classification_accuracy: 0.3484 - classification_loss: 6.7363 - loss: 34.0929 - regression_loss: 27.3564 - regression_mae: 3.9781 - val_classification_accuracy: 0.4335 - val_classification_loss: 5.5613 - val_loss: 12.3939 - val_regression_loss: 6.8067 - val_regression_mae: 2.0346\n",
            "Epoch 14/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - classification_accuracy: 0.3724 - classification_loss: 6.9511 - loss: 23.5181 - regression_loss: 16.5669 - regression_mae: 3.1556 - val_classification_accuracy: 0.0550 - val_classification_loss: 12.9565 - val_loss: 25.3053 - val_regression_loss: 12.3793 - val_regression_mae: 2.9712\n",
            "Epoch 15/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - classification_accuracy: 0.3807 - classification_loss: 7.4460 - loss: 23.0962 - regression_loss: 15.6500 - regression_mae: 3.0672 - val_classification_accuracy: 0.4315 - val_classification_loss: 6.2487 - val_loss: 27.7911 - val_regression_loss: 21.5559 - val_regression_mae: 3.8995\n",
            "Epoch 16/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - classification_accuracy: 0.4029 - classification_loss: 8.5895 - loss: 29.3435 - regression_loss: 20.7539 - regression_mae: 3.5608 - val_classification_accuracy: 0.6420 - val_classification_loss: 7.2540 - val_loss: 15.2535 - val_regression_loss: 7.9845 - val_regression_mae: 2.2556\n",
            "Epoch 17/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - classification_accuracy: 0.4205 - classification_loss: 10.0830 - loss: 46.5609 - regression_loss: 36.4773 - regression_mae: 4.4056 - val_classification_accuracy: 0.4075 - val_classification_loss: 7.3382 - val_loss: 17.1235 - val_regression_loss: 9.7604 - val_regression_mae: 2.5541\n",
            "Epoch 18/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - classification_accuracy: 0.4385 - classification_loss: 9.4418 - loss: 31.8742 - regression_loss: 22.4326 - regression_mae: 3.4625 - val_classification_accuracy: 0.0700 - val_classification_loss: 17.7493 - val_loss: 51.3433 - val_regression_loss: 33.6203 - val_regression_mae: 4.7527\n",
            "Epoch 19/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - classification_accuracy: 0.4338 - classification_loss: 11.3204 - loss: 80.5784 - regression_loss: 69.2584 - regression_mae: 5.4908 - val_classification_accuracy: 0.1330 - val_classification_loss: 16.9458 - val_loss: 34.9203 - val_regression_loss: 17.9615 - val_regression_mae: 3.2731\n",
            "Epoch 20/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - classification_accuracy: 0.4528 - classification_loss: 12.0604 - loss: 39.8215 - regression_loss: 27.7612 - regression_mae: 3.9753 - val_classification_accuracy: 0.0325 - val_classification_loss: 29.5861 - val_loss: 44.5397 - val_regression_loss: 15.0115 - val_regression_mae: 3.2190\n",
            "Epoch 21/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - classification_accuracy: 0.4745 - classification_loss: 16.6135 - loss: 43.1562 - regression_loss: 26.5453 - regression_mae: 3.7156 - val_classification_accuracy: 0.8120 - val_classification_loss: 13.5971 - val_loss: 164.0905 - val_regression_loss: 150.7242 - val_regression_mae: 10.0326\n",
            "Epoch 22/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - classification_accuracy: 0.4853 - classification_loss: 14.5989 - loss: 148.0728 - regression_loss: 133.4725 - regression_mae: 8.2842 - val_classification_accuracy: 0.4065 - val_classification_loss: 11.2786 - val_loss: 22.2397 - val_regression_loss: 10.9064 - val_regression_mae: 2.5522\n",
            "Epoch 23/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - classification_accuracy: 0.4765 - classification_loss: 14.7023 - loss: 50.1464 - regression_loss: 35.4429 - regression_mae: 4.4238 - val_classification_accuracy: 0.2390 - val_classification_loss: 20.1546 - val_loss: 28.8476 - val_regression_loss: 8.7181 - val_regression_mae: 2.3110\n",
            "Epoch 24/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - classification_accuracy: 0.4904 - classification_loss: 18.7972 - loss: 47.9729 - regression_loss: 29.1755 - regression_mae: 3.9758 - val_classification_accuracy: 0.3970 - val_classification_loss: 16.0417 - val_loss: 32.7397 - val_regression_loss: 16.6956 - val_regression_mae: 3.4518\n",
            "Epoch 25/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - classification_accuracy: 0.4913 - classification_loss: 20.1451 - loss: 90.1888 - regression_loss: 70.0416 - regression_mae: 5.7313 - val_classification_accuracy: 0.4675 - val_classification_loss: 17.6600 - val_loss: 33.5433 - val_regression_loss: 15.8144 - val_regression_mae: 2.9308\n",
            "Epoch 26/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - classification_accuracy: 0.5219 - classification_loss: 23.3160 - loss: 73.6734 - regression_loss: 50.3579 - regression_mae: 5.2929 - val_classification_accuracy: 0.4550 - val_classification_loss: 20.8899 - val_loss: 38.8219 - val_regression_loss: 17.9515 - val_regression_mae: 3.2772\n",
            "Epoch 27/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - classification_accuracy: 0.5239 - classification_loss: 25.8183 - loss: 110.8996 - regression_loss: 85.0844 - regression_mae: 6.4404 - val_classification_accuracy: 0.3185 - val_classification_loss: 31.1533 - val_loss: 204.2980 - val_regression_loss: 173.8294 - val_regression_mae: 12.0227\n",
            "Epoch 28/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - classification_accuracy: 0.5411 - classification_loss: 26.0078 - loss: 128.7281 - regression_loss: 102.7291 - regression_mae: 7.7119 - val_classification_accuracy: 1.0000 - val_classification_loss: 59.5638 - val_loss: 82.1065 - val_regression_loss: 22.4423 - val_regression_mae: 3.6836\n",
            "Epoch 29/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - classification_accuracy: 0.5496 - classification_loss: 35.5507 - loss: 237.2190 - regression_loss: 201.6697 - regression_mae: 9.7338 - val_classification_accuracy: 0.4540 - val_classification_loss: 32.3451 - val_loss: 85.9772 - val_regression_loss: 53.6857 - val_regression_mae: 5.7513\n",
            "Epoch 30/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - classification_accuracy: 0.5416 - classification_loss: 36.2734 - loss: 78.7599 - regression_loss: 42.4895 - regression_mae: 4.8914 - val_classification_accuracy: 0.8240 - val_classification_loss: 35.2361 - val_loss: 240.9235 - val_regression_loss: 206.2289 - val_regression_mae: 11.0205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predictions_regression, y_predictions_classification = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Crkz5hAn8XVh",
        "outputId": "3bd4dbb1-836d-44d9-b941-ab869c0a16fb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
          ]
        }
      ]
    }
  ]
}